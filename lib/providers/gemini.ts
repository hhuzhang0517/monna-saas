import { GoogleGenerativeAI } from "@google/generative-ai";
import { putAndGetUrl, putAndGetPublicUrl } from "@/lib/storage";
import crypto from "crypto";

// 初始化Gemini客户端
if (!process.env.GEMINI_API_KEY) {
  throw new Error("GEMINI_API_KEY environment variable is not set");
}
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

export async function generateImageGemini(prompt: string, referenceImageUrl?: string, referenceImageUrl2?: string) {
  console.log("🤖 Using Gemini 2.5 Flash Image (Nano Banana) for image generation");
  console.log("🎨 Starting Gemini image generation:", {
    prompt,
    hasReferenceImage: !!referenceImageUrl,
    hasSecondReferenceImage: !!referenceImageUrl2
  });

  try {
    // 尝试使用不同的模型进行图片生成
    let model;
    let modelName = "gemini-2.5-flash-image-preview";
    
    try {
      model = genAI.getGenerativeModel({
        model: modelName,
        generationConfig: {
          temperature: 0.8,
          topP: 0.9,
          topK: 40,
          maxOutputTokens: 1290, // 每张图片1290 tokens
        }
      });
    } catch (modelError) {
      console.log("⚠️ Primary model failed, trying alternative model...");
      modelName = "gemini-2.5-flash";
      model = genAI.getGenerativeModel({
        model: modelName,
        generationConfig: {
          temperature: 0.8,
          topP: 0.9,
          topK: 40,
          maxOutputTokens: 1290,
        }
      });
    }
    
    console.log("🔧 Model configuration:", {
      modelName,
      temperature: 0.8,
      maxOutputTokens: 1290
    });

    // 构建内容数组
    const contents: any[] = [];

    // 处理参考图片
    if (referenceImageUrl && referenceImageUrl2) {
      // 双图片模式：处理两张参考图片进行合成
      console.log("🖼️🖼️ Adding two reference images for anime merge/composition");

      // 下载第一张图片
      const imageResponse1 = await fetch(referenceImageUrl);
      if (!imageResponse1.ok) {
        throw new Error(`Failed to fetch first reference image: ${imageResponse1.statusText}`);
      }

      const imageBuffer1 = await imageResponse1.arrayBuffer();
      const base64Image1 = Buffer.from(imageBuffer1).toString('base64');
      const mimeType1 = imageResponse1.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image1,
          mimeType: mimeType1
        }
      });

      // 下载第二张图片
      const imageResponse2 = await fetch(referenceImageUrl2);
      if (!imageResponse2.ok) {
        throw new Error(`Failed to fetch second reference image: ${imageResponse2.statusText}`);
      }

      const imageBuffer2 = await imageResponse2.arrayBuffer();
      const base64Image2 = Buffer.from(imageBuffer2).toString('base64');
      const mimeType2 = imageResponse2.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image2,
          mimeType: mimeType2
        }
      });

      // 为双图片合成添加提示词
      contents.push({
        text: prompt
      });
    } else if (referenceImageUrl) {
      // 单图片模式：处理一张参考图片
      console.log("🖼️ Adding reference image for image editing/composition");

      // 下载参考图片并转换为Base64
      const imageResponse = await fetch(referenceImageUrl);
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch reference image: ${imageResponse.statusText}`);
      }

      const imageBuffer = await imageResponse.arrayBuffer();
      const base64Image = Buffer.from(imageBuffer).toString('base64');
      const mimeType = imageResponse.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image,
          mimeType: mimeType
        }
      });

      // 为图像编辑添加提示词
      contents.push({
        text: prompt
      });
    } else {
      // 纯文本生成图片
      contents.push({
        text: prompt
      });
    }

    console.log("📤 Sending request to Gemini 2.5 Flash Image API");

    // 发送请求到Gemini API
    const result = await model.generateContent(contents);
    const response = await result.response;

    // 检查响应
    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error("No image generated by Gemini");
    }

    console.log("🔍 Gemini response candidates:", candidates.length);

    // 获取生成的图片
    const candidate = candidates[0];
    
    // 添加详细的调试信息
    console.log("🔍 Gemini response structure:", JSON.stringify({
      hasContent: !!candidate.content,
      hasParts: !!candidate.content?.parts,
      partsLength: candidate.content?.parts?.length || 0,
      partsStructure: candidate.content?.parts?.map((part: any) => ({
        hasText: !!part.text,
        hasInlineData: !!part.inlineData,
        hasExectuableCode: !!part.executableCode,
        hasCodeExecutionResult: !!part.codeExecutionResult,
        keys: Object.keys(part)
      })) || []
    }, null, 2));
    
    if (!candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
      console.log("❌ No content or parts found in candidate:", JSON.stringify(candidate, null, 2));
      throw new Error("No image content in Gemini response");
    }

    // 查找图片部分
    const imagePart = candidate.content.parts.find((part: any) => part.inlineData);
    if (!imagePart || !imagePart.inlineData) {
      console.log("❌ No inline data found, response parts:", JSON.stringify(candidate.content.parts, null, 2));
      throw new Error("No image data found in Gemini response");
    }

    console.log("🎯 Gemini generated image successfully");

    // 解码Base64图片数据
    const imageData = imagePart.inlineData.data;
    const mimeType = imagePart.inlineData.mimeType || "image/png";

    // 转换为Uint8Array
    const imageBuffer = Buffer.from(imageData, 'base64');
    const bytes = new Uint8Array(imageBuffer);

    console.log("💾 Uploading generated image to storage, size:", bytes.length, "bytes");

    // 存储到Supabase Storage - 使用优化的公共URL版本提高上传速度
    const fileName = `gemini/${crypto.randomUUID()}.${mimeType.includes('jpeg') ? 'jpg' : 'png'}`;
    const url = await putAndGetPublicUrl(fileName, bytes, mimeType);

    console.log("✅ Gemini image generation completed, URL:", url);

    return {
      url: url,
      optimizedPrompt: prompt
    };

  } catch (error) {
    console.error("❌ Gemini image generation failed:", error);
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`Gemini图片生成失败: ${errorMessage}`);
  }
}


/**
 * 使用Gemini生成结构化的镜头规划JSON
 */
export async function generateShotPlanWithGemini(
  userPrompt: string, 
  targetSeconds: number = 30, 
  ratio: string = '1280:768'
): Promise<any> {
  console.log(`🎬 Generating shot plan with Gemini for: "${userPrompt}" (${targetSeconds}s, ${ratio})`);
  
  try {
    const model = genAI.getGenerativeModel({ 
      model: "gemini-2.5-flash", // 使用最新的Gemini模型
      generationConfig: {
        temperature: 0.7,
        topP: 0.8,
        topK: 40,
        maxOutputTokens: 4096, // 增加输出长度限制
      }
    });
        const systemPrompt = `You are a professional cinematographer. Break down the user's high-level prompt into coherent shot sequences.

Requirements:
1. Follow Runway model duration constraints: gen4_turbo recommends 5s or 10s per segment
2. Total duration should approach target_seconds, ensure narrative continuity and subject consistency between shots
3. Use positive phrasing only: prompts that describe what should happen in shot
4. Maintain character and scene consistency
5. ALL shot prompts MUST be in English for video generation model compatibility
6. Use direct, simple, and easily understood prompts (max 50 words per shot to avoid Runway errors)
7. Focus on describing the motion, rather than the input image:Both text and image inputs are considered part of your prompt. Reiterating elements that exist within the image in high detail can lead to reduced motion or unexpected results in the output.
8. Use basic camera terms: "static", "handheld", "tracking"
9. Focus on concrete visual elements, not abstract concepts
10. Avoid conversational or command-based prompts:describe how the elements should appear or disappear from the scene
11. Avoid overly complex prompts: simple description of the desired motion for a single scene
12. AVOID words that might trigger content policies: "spiritual", "energy", "pulsating", "mystical", "magical", "ethereal"
13. Use realistic, grounded descriptions instead of fantasy elements

Output strictly in the following JSON format with NO other text:

{
  "ratio": "${ratio}",
  "total_seconds": ${targetSeconds},
  "shots": [
    {
      "id": 1,
      "prompt": "Concise but detailed English description of the first shot",
      "duration_s": 10,
      "camera": "static"
    }
  ]
}`;

    const userInput = `User Prompt: ${userPrompt}
Target Duration (seconds): ${targetSeconds}
Aspect Ratio: ${ratio}

Please break down this prompt into multiple coherent shots, ensuring the total duration meets the target requirement. Remember: ALL shot descriptions must be in English.`;

    const result = await model.generateContent([
      { text: systemPrompt },
      { text: userInput }
    ]);

    const response = await result.response;
    const text = response.text();
    
    console.log('🤖 Gemini raw response:', text);

    // 尝试解析JSON
    let plan;
    try {
      // 清理响应文本，移除可能的markdown代码块标记
      let cleanText = text.replace(/```json\s*|\s*```/g, '').trim();
      
      // 检查JSON是否被截断，如果是则尝试修复
      if (!cleanText.endsWith('}') && !cleanText.endsWith(']}')) {
        console.warn('⚠️ Detected truncated JSON, attempting to fix...');
        
        // 找到最后一个完整的镜头对象
        const lastCompleteShot = cleanText.lastIndexOf('    }');
        if (lastCompleteShot !== -1) {
          // 截取到最后一个完整镜头，然后补全JSON结构
          cleanText = cleanText.substring(0, lastCompleteShot + 5) + '\n  ]\n}';
          console.log('🔧 Repaired JSON structure');
        } else {
          // 如果找不到完整的镜头，使用降级方案
          throw new Error('JSON截断严重，无法修复');
        }
      }
      
      plan = JSON.parse(cleanText);
    } catch (parseError) {
      console.error('❌ Failed to parse Gemini JSON response:', parseError);
      console.error('Raw text:', text);
      
      // 尝试从截断的JSON中提取可用的镜头信息
      try {
        const shotMatches = text.match(/"id":\s*(\d+),\s*"prompt":\s*"([^"]*)",\s*"duration_s":\s*(\d+),\s*"camera":\s*"([^"]*)"/g);
        if (shotMatches && shotMatches.length > 0) {
          console.log('🔧 Attempting to extract shots from partial JSON...');
          const extractedShots = shotMatches.map((match, index) => {
            const shotMatch = match.match(/"id":\s*(\d+),\s*"prompt":\s*"([^"]*)",\s*"duration_s":\s*(\d+),\s*"camera":\s*"([^"]*)"/);
            if (shotMatch) {
              return {
                id: parseInt(shotMatch[1]),
                prompt: shotMatch[2],
                duration_s: parseInt(shotMatch[3]),
                camera: shotMatch[4]
              };
            }
            return null;
          }).filter(shot => shot !== null);
          
          if (extractedShots.length > 0) {
            plan = {
              ratio: ratio,
              total_seconds: targetSeconds,
              shots: extractedShots
            };
            console.log(`✅ Extracted ${extractedShots.length} shots from partial JSON`);
          } else {
            throw new Error('无法从截断的JSON中提取镜头信息');
          }
        } else {
          throw new Error('Gemini返回的JSON格式有误');
        }
      } catch (extractError) {
        console.error('❌ JSON extraction also failed:', extractError);
        throw new Error('Gemini返回的JSON格式有误');
      }
    }
    
    // 量化时长到Runway支持的值（5s/10s）
    if (plan.shots && Array.isArray(plan.shots)) {
      plan.shots = plan.shots.map((shot: any) => {
        const quantizedDuration = shot.duration_s <= 7 ? 5 : shot.duration_s <= 15 ? 10 : Math.min(30, shot.duration_s);
        return { ...shot, duration_s: quantizedDuration };
      });
    }

    console.log(`📋 Generated shot plan with Gemini:`, {
      totalShots: plan.shots?.length || 0,
      totalDuration: plan.shots?.reduce((sum: number, shot: any) => sum + shot.duration_s, 0) || 0,
      shots: plan.shots?.map((s: any) => ({ id: s.id, duration: s.duration_s, camera: s.camera })) || []
    });

    return plan;
    
  } catch (error) {
    console.error('❌ Gemini API failed:', error);
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`Gemini镜头规划失败: ${errorMessage}`);
  }
}